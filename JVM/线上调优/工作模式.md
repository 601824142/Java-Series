# JVM 工作模式

在 `java -version` 命令中，我们能够了解当前的 JVM 类型与工作模式：

![](https://coding.net/u/hoteam/p/Cache/git/raw/master/2016/8/2/65956595-CEC6-4E9A-B59E-2E312F4A19E6.png)

第三行的输出中可以看到：JVM 的名字(HotSpot)、类型(Client)和 build ID(24.79-b02) 。除此之外，我们还知道 JVM 以混合模式(mixed mode)在运行，这是 HotSpot 默认的运行模式，意味着 JVM 在运行时可以动态的把字节码编译为本地代码。我们也可以看到类数据共享(class data sharing)是开启(即第三行最后的 sharing)的。类数据共享(class data sharing)是一种在只读缓存(在 jsa 文件中，”Java Shared Archive”)中存储 JRE 的系统类，被所有 Java 进程的类加载器用来当做共享资源，它可能在经常从 jar 文档中读所有的类数据的情况下显示出性能优势。

**-Xcomp 代表编译模式(compiled mode)**，与它(-Xint)正好相反，JVM 在第一次使用时会把**所有的字节码编译成本地代码**，从而带来最大程度的优化。这听起来不错，因为这完全绕开了缓慢的解释器。然而，很多应用在使用-Xcomp 也会有一些性能损失，但是这比使用-Xint 损失的少，原因是-Xcomp 没有让 JVM 启用 JIT 编译器的全部功能。因此在上图中，我们并没有看到-Xcomp 比-Xmixed 快多少。

**-Xmixed 代表混合模式(mixed mode)**，前面也提到了，混合模式是 JVM 的默认工作模式。它会同时使用编译模式和解释模式。**对于字节码中多次被调用的部分，JVM 会将其编译成本地代码以提高执行效率；而被调用很少(甚至只有一次)的方法在解释模式下会继续执行，从而减少编译和优化成本。**JIT 编译器在运行时创建方法使用文件，然后一步一步的优化每一个方法，有时候会主动的优化应用的行为。这些优化技术，比如积极的分支预测(optimistic branch prediction)，如果不先分析应用就不能有效的使用。这样将频繁调用的部分提取出来，编译成本地代码，也就是在应用中构建某种热点(**即 HotSpot，\*\***这也是 HotSpot JVM 名字的由来**)。**使用混合模式可以获得最好的执行效率\*\*。

那么，Client JVM 和 Server JVM 到底在哪些方面不同呢？当虚拟机运行在-client 模式的时候,使用的是一个代号为 C1 的轻量级编译器, 而-server 模式启动的虚拟机采用相对重量级,代号为 C2 的编译器. C2 比 C1 编译器编译的相对彻底，服务起来之后,性能更高。-Server VM 启动时，速度较慢，但是一旦运行起来后，性能将会有很大的提升。

很明显，Client VM 的编译器没有像 Server VM 一样执行许多复杂的优化算法，因此，它在分析和编译代码片段的时候更快。而 Server VM 则包含了一个高级的编译器，该编译器支持许多和在 C++编译器上执行的一样的优化，同时还包括许多传统的编译器无法实现的优化。

从 J2SE 5.0 开始，当一个应用启动的时候，加载器会尝试去检测应用是否运行在 “server-class” 的机器上，如果是，则使用 Java HotSpot Server Virtual Machine (server VM)而不是 Java HotSpot Client Virtual Machine (client VM)。这样做的目的是提高执行效率，即使没有为应用显式配置 VM。下面这张图展示了各个平台的默认的 JVM(注意：—代表不提供该平台的 JVM )：

![](http://static.oschina.net/uploads/space/2015/0918/213602_GsBV_1434710.png)
